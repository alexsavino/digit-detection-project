{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vgg16\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]\n",
    "\n",
    "# --- DEFINING THE ORIGINAL MODEL ---\n",
    "class CNN(nn.Module):\n",
    "    # Defines Model Layers + General Structure\n",
    "    def __init__(self):\n",
    "        # (\"CNN\" --> made up of convolutional layers, pooling layers, and fully connected layers (i.e. each node from the previous layer factors into / is connected to the fully-connected layer))\n",
    "        # (\"conv layer\" --> uses filters to detect features in images)\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)                                                                     # CONV: 3 input channels (RGB), 6 output filters,  5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)                                                                    # CONV: 6 input filters,        16 output filters, 5x5 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)                                                                      # MAX-POOLING: 2x2 pool size\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)                                                               # FC LAYER: 16 filters * 5x5 image size after pooling = 400 input nodes\n",
    "        self.fc2 = nn.Linear(120, 84)                                                                       # FC LAYER: 120 nodes to 84\n",
    "        self.fc3 = nn.Linear(84, 11)                                                                        # OUTPUT: 84 nodes to 11 classes (digits 0-9 + \"no digit\" class)\n",
    "\n",
    "    # Defines How Input Data Flows Through Layers During Prediction, (effectively telling the model by hand how to move data through the layers*)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))                                                                # applying conv. + max-pooling (using RELU!!)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)                                                                             # flattening the tensor so it can pass through the FC layers\n",
    "        x = F.relu(self.fc1(x))                                                                             # applying the FC layers (again using RELU!!)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)                                                                                     # output prediction\n",
    "        return x\n",
    "\n",
    "# --- DEFINING THE VGG16 MODEL FOR FINE-TUNING ---\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=11):                                                                     # there will be 0-9 + non-digit class, i.e. 11 classes\n",
    "        super(VGG16, self).__init__()\n",
    "        vgg = vgg16(pretrained=True)                                                                        # loading in the pre-trained weights\n",
    "        \n",
    "        vgg.features[0] = nn.Conv2d(3, 64, kernel_size=3, padding=1)                                        # CHANGING THE FIRST LAYER SO THAT IT ACCEPTS ONLY 32X32 IMAGES\n",
    "        self.features = vgg.features\n",
    "        \n",
    "        self.classifier = nn.Sequential( # modifying the classifier to match our input size and number of output classes??? COME BACK!!!\n",
    "            nn.Linear(512 * 1 * 1, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        ) \n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):                                                                                   # defines data flow ... i think?\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# --- DEFINING A FUNCTION TO GENERATE RANDOM NOISE IMAGES TO TRAIN FOR NON-DIGIT EXAMPLES!!! ---\n",
    "def generate_non_digit_samples(transform, num_samples):\n",
    "    SAMPLES = []\n",
    "    LABELS = []\n",
    "    \n",
    "    for _ in range(num_samples//3):\n",
    "        img = np.random.randint(0, 256, (32, 32, 3), dtype=np.uint8)\n",
    "        img = Image.fromarray(img)\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        SAMPLES.append(img)\n",
    "        LABELS.append(10)\n",
    "    \n",
    "    for _ in range(num_samples//3):\n",
    "        img = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "        for i in range(32):\n",
    "            for j in range(32):\n",
    "                r = (i*8) % 256\n",
    "                g = (j*8) % 256\n",
    "                b = ((i+j) * 4) % 256\n",
    "                img[i, j] = [r, g, b]\n",
    "        img = Image.fromarray(img)\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        SAMPLES.append(img)\n",
    "        LABELS.append(10)\n",
    "    \n",
    "    for _ in range(num_samples // 3):\n",
    "        img = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "        pattern_type = random.randint(0, 1)\n",
    "        \n",
    "        if pattern_type==0:                                                                               # stripe pattern*\n",
    "            stripe_width = random.randint(1, 5)\n",
    "            color1 = [random.randint(0, 255) for _ in range(3)]\n",
    "            color2 = [random.randint(0, 255) for _ in range(3)]\n",
    "            for i in range(32):\n",
    "                for j in range(32):\n",
    "                    if (i // stripe_width) % 2 == 0:\n",
    "                        img[i,j] = color1\n",
    "                    else:\n",
    "                        img[i,j] = color2\n",
    "        \n",
    "        elif pattern_type==1:                                                                             # checkerboard random pattern\n",
    "            square_size = random.randint(2, 8)\n",
    "            color1 = [random.randint(0, 255) for _ in range(3)]\n",
    "            color2 = [random.randint(0, 255) for _ in range(3)]\n",
    "            for i in range(32):\n",
    "                for j in range(32):\n",
    "                    if ((i // square_size) + (j // square_size)) % 2 == 0:\n",
    "                        img[i,j] = color1\n",
    "                    else:\n",
    "                        img[i,j] = color2\n",
    "        \n",
    "        img = Image.fromarray(img)\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        SAMPLES.append(img)\n",
    "        LABELS.append(10)\n",
    "    \n",
    "    return SAMPLES, LABELS\n",
    "\n",
    "\n",
    "# --- DEFINING A FUNCTION TO LOAD IN / GET READY DATA AND GENERAL TECH FOR MODEL BUILDING ---\n",
    "def load_and_prepare_mb_dataset(model_type, lf, lr, bs):\n",
    "    torch.manual_seed(42)                                                                                    # generating random seeds for reproducibility!\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    transform = transforms.Compose([                                                                        # defining transformations... i.e. images --> tensors \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Really Loading + Generating + Organizing Data\n",
    "    training = torchvision.datasets.SVHN(root='./data', split='train', download=True, transform=transform)  # loading in the CROPPED DIGIT DATASETS ALWAYS for training!\n",
    "    testing = torchvision.datasets.SVHN(root='./data',  split='test',  download=True, transform=transform)\n",
    "    non_digit_train_samples, non_digit_train_labels = generate_non_digit_samples(transform, len(training)//2)          # (generating those non-digit examples as well)\n",
    "    non_digit_test_samples,  non_digit_test_labels =  generate_non_digit_samples(transform, len(testing)//2)\n",
    "\n",
    "    svhn_train_samples = []\n",
    "    svhn_train_labels = []\n",
    "    svhn_test_samples = []\n",
    "    svhn_test_labels = []\n",
    "    for i in range(len(training)):\n",
    "        img, label = training[i]\n",
    "        svhn_train_samples.append(img)\n",
    "        svhn_train_labels.append(int(label))\n",
    "    for i in range(len(testing)):\n",
    "        img, label = testing[i]\n",
    "        svhn_test_samples.append(img)\n",
    "        svhn_test_labels.append(int(label))\n",
    "\n",
    "    train_samples = svhn_train_samples + non_digit_train_samples                                            # combining all data to create full digit + non-digit datasets\n",
    "    train_labels = svhn_train_labels + non_digit_train_labels\n",
    "    test_samples = svhn_test_samples + non_digit_test_samples\n",
    "    test_labels = svhn_test_labels + non_digit_test_labels\n",
    "    train_dataset = SimpleDataset(train_samples, train_labels)\n",
    "    test_dataset = SimpleDataset(test_samples, test_labels)\n",
    "\n",
    "\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size                                                              # splitting into single time validation + training\n",
    "    train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "    batch_size = bs\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)                            # creating the dataloaders, i.e. things that efficiently load + batch during training\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # Instantiating Literally Everything (i.e. Model, Loss, Optimizer, etc)\n",
    "    if model_type == 'original':\n",
    "        model = CNN()\n",
    "    elif model_type == 'vgg16':\n",
    "        model = VGG16()\n",
    "\n",
    "    if lf=='cross-entropy':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif lf=='mean-squared':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif lf=='multi-margin':\n",
    "        criterion = nn.MultiMarginLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = model.to(device)\n",
    "    return model, train_loader, val_loader, test_loader, device\n",
    "\n",
    "\n",
    "# --- DEFINING A FUNCTION TO ACTUALLY TRAIN A MODEL ---\n",
    "def train_model(model, train_loader, val_loader, test_loader, device, lf, lr):\n",
    "    if lf=='cross-entropy':                                                                                 # declaring all the old model stuff wrt our hyperparam inputs\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif lf=='mean-squared':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif lf=='multi-margin':\n",
    "        criterion = nn.MultiMarginLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    best_val_acc = 0.0\n",
    "    associated_best_train_acc = 0.0\n",
    "\n",
    "    history = {\n",
    "        'train_acc': [],                                                                                    # stores training + validation accuracies \n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        # print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # MODEL IN TRAINING .................................................................................\n",
    "        model.train()\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "        \n",
    "        epoch_acc = running_corrects.double() / total_samples\n",
    "        history['train_acc'].append(epoch_acc.item())\n",
    "        \n",
    "        # MODEL IN (VALIDATION) EVALUATION ..................................................................\n",
    "        model.eval()\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                total_samples += inputs.size(0)\n",
    "        \n",
    "        epoch_acc = running_corrects.double() / total_samples\n",
    "        history['val_acc'].append(epoch_acc.item())\n",
    "                \n",
    "        # SAVING THE BEST MODEL PERFORMANCE .................................................................\n",
    "        if epoch_acc > best_val_acc:                                                                        # best = best performing on the validation set\n",
    "            best_val_acc = epoch_acc\n",
    "            associated_best_train_acc = history['train_acc'][-1]\n",
    "            \n",
    "            if model_name == 'original':\n",
    "                path = os.path.join(\"..\", \"current-models\", \"original\", f\"{lf}-{str(lr)}-{str(bs)}.pth\")\n",
    "                torch.save(best_model_state, path)\n",
    "            elif model_name == 'vgg16':\n",
    "                path = os.path.join(\"..\", \"current-models\", \"vgg16\", f\"{lf}-{str(lr)}-{str(bs)}.pth\")\n",
    "                torch.save(best_model_state, path)\n",
    "            # torch.save(model.state_dict(), 'best_digit_classifier.pth')\n",
    "\n",
    "    return model, (1-associated_best_train_acc, 1-best_val_acc)                                             # returning ERROR RATE, not accuracy anymore\n",
    "\n",
    "\n",
    "# --- DEFINING A FUNCTION TO ACTUALLY EVALUATE A MODEL on TESTING DATA EXPLICITLY ---\n",
    "def evaluate_model(model, dataloader):\n",
    "    # MODEL IN (TESTING) EVALUATION .........................................................................\n",
    "    model.eval()\n",
    "    \n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    test_acc = running_corrects.double()/total_samples\n",
    "    return 1-test_acc.item()\n",
    "\n",
    "\n",
    "\n",
    "def model_development_and_evaluation_pipeline(model_type, lf, lr, bs):\n",
    "\n",
    "    model, train_loader, val_loader, test_loader, device = load_and_prepare_mb_dataset(model_type, lf, lr, bs)       # actually TRAINING the model\n",
    "    model, (train_er, best_val_er) = train_model(model, train_loader, val_loader, test_loader, device, lf, lr)\n",
    "    model.load_state_dict(torch.load('best_digit_classifier.pth'))                                          # loading the BEST one\n",
    "    test_er = evaluate_model(model, test_loader)\n",
    "\n",
    "    return train_er, best_val_er, test_er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_hyperparameters(model_type, lf_list, lr_list, bs_list):\n",
    "\n",
    "    # {key: value} == {(loss_function, learning_rate, batch_size): \n",
    "    #                         (training_error, validation_error, testing_error))}\n",
    "    hyperparameter_performance_results = {}\n",
    "\n",
    "    i = 0\n",
    "    for loss_function in lf_list:\n",
    "        for learning_rate in lr_list:\n",
    "            for batch_size in bs_list:\n",
    "                print(\"iteration: \", i)\n",
    "                hyperparameter_performance_results[(loss_function, learning_rate, batch_size)] = model_development_and_evaluation_pipeline(model_type, lf, lr, bs)\n",
    "                # hyperparameter_performance_results[(loss_function, learning_rate, batch_size)] = train_and_evaluate_model(base_dataset_path, model_name, loss_function, learning_rate, batch_size)\n",
    "                i += 1\n",
    "\n",
    "    return hyperparameter_performance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Non-digit with 95.07% confidence\n"
     ]
    }
   ],
   "source": [
    "def predict_single_image(model, image_path):\n",
    "    # Load and preprocess the image\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    \n",
    "    # Same preprocessing as during training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Apply transforms\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Move to the same device as the model\n",
    "    device = next(model.parameters()).device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, prediction = torch.max(probabilities, 1)\n",
    "    \n",
    "    # Convert to standard Python types\n",
    "    predicted_class = prediction.item()\n",
    "    confidence_score = confidence.item()\n",
    "    \n",
    "    # Map class index to label\n",
    "    class_name = 'Non-digit' if predicted_class == 10 else str(predicted_class)\n",
    "    \n",
    "    return {\n",
    "        'class': class_name,\n",
    "        'class_index': predicted_class,\n",
    "        'confidence': confidence_score,\n",
    "        'probabilities': probabilities[0].cpu().numpy()  # All class probabilities\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "model = VGG16()\n",
    "model.load_state_dict(torch.load('current-models/vgg16/best_digit_classifier.pth'))\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Then predict on a single image\n",
    "result = predict_single_image(model, 'test_images/special-test-2.jpg')\n",
    "print(f\"Prediction: {result['class']} with {result['confidence']:.2%} confidence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_proj_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
